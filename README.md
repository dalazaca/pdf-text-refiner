# PDF Analyzer

Script en Python para an√°lisis h√≠brido de errores en documentos PDF usando LanguageTool y Ollama LLMs.

## Caracter√≠sticas

Combina dos m√©todos complementarios para an√°lisis exhaustivo:

### LanguageTool (An√°lisis R√°pido)
- Detecci√≥n de errores ortogr√°ficos y gramaticales b√°sicos
- Verificaci√≥n de redundancias
- An√°lisis de concordancia
- Procesamiento r√°pido y eficiente

### Ollama LLM (An√°lisis Profundo)
- An√°lisis contextual de redacci√≥n
- Detecci√≥n de errores de coherencia y estilo
- Sugerencias inteligentes basadas en contexto
- Identificaci√≥n de problemas de construcci√≥n de frases
- 100% local y privado (no env√≠a datos a internet)

## Instalaci√≥n

### Requisitos previos

- Python 3.7 o superior
- UV (gestor de paquetes Python)
- Ollama instalado y ejecut√°ndose

### Instalar dependencias

```bash
uv add pdfminer.six language-tool-python tqdm ollama
```

Opcionalmente, puedes crear un entorno virtual aislado:

```bash
uv venv .venv
source .venv/bin/activate  # En Linux/macOS
# .venv\Scripts\activate   # En Windows
uv add pdfminer.six language-tool-python tqdm ollama
```

## Tabla de dependencias

| Paquete | Versi√≥n m√≠nima | Comentario |
|---------|----------------|------------|
| `pdfminer.six` | ‚â• 20201018 | Extracci√≥n robusta de texto desde PDF |
| `language-tool-python` | ‚â• 2.7.0 | Interfaz de LanguageTool para correcci√≥n ortogr√°fica |
| `tqdm` | ‚â• 4.0 | Barra de progreso en consola |
| `ollama` | ‚â• 0.1.0 | Cliente oficial de Ollama para Python |

## Configuraci√≥n de Ollama

**IMPORTANTE**: Ollama debe ser accesible desde WSL. Sigue estos pasos:

### Paso 1: Verificar la conexi√≥n

```bash
python test_ollama_connection.py
```

### Paso 2: Configurar Ollama en Windows (si falla)

1. Abre PowerShell como Administrador
2. Ejecuta:
   ```powershell
   [System.Environment]::SetEnvironmentVariable('OLLAMA_HOST', '0.0.0.0:11434', 'User')
   ```
3. Reinicia Ollama
4. Permite el firewall:
   ```powershell
   New-NetFirewallRule -DisplayName "Ollama WSL" -Direction Inbound -LocalPort 11434 -Protocol TCP -Action Allow
   ```

### Paso 3: Instalar un modelo

```powershell
ollama pull llama3.2:3b
```

üìñ **Gu√≠a completa**: Consulta `CONFIGURACION_OLLAMA.md` para m√°s detalles.

## Uso

### Sintaxis b√°sica

```bash
python pdf_analyzer.py --pdf documento.pdf
```

### Par√°metros

- `--pdf`: **(Obligatorio)** Ruta al archivo PDF a analizar
- `--out`: **(Opcional)** Ruta del archivo de salida (default: `errores_hibrido.txt`)
- `--start-page`: **(Opcional)** P√°gina de inicio para el an√°lisis (default: primera p√°gina)
- `--end-page`: **(Opcional)** P√°gina final para el an√°lisis (default: √∫ltima p√°gina)
- `--debug`: **(Opcional)** Activa modo debug: guarda el texto extra√≠do de cada p√°gina
- `--model`: **(Opcional)** Modelo de Ollama a usar (default: `llama3.2:3b`)
- `--ollama-host`: **(Opcional)** URL del servidor Ollama (auto-detecta desde WSL)

### Ejemplos

```bash
# An√°lisis b√°sico con configuraci√≥n por defecto
python pdf_analyzer.py --pdf documento.pdf

# Especificar archivo de salida personalizado
python pdf_analyzer.py --pdf tesis.pdf --out resultados_tesis.txt

# Analizar solo un rango de p√°ginas (ejemplo: p√°ginas 10 a 20)
python pdf_analyzer.py --pdf libro.pdf --start-page 10 --end-page 20

# Usar un modelo m√°s potente
python pdf_analyzer.py --pdf articulo.pdf --model mistral:latest

# Modo debug para inspeccionar el texto extra√≠do
python pdf_analyzer.py --pdf documento.pdf --debug

# Especificar host de Ollama personalizado
python pdf_analyzer.py --pdf doc.pdf --ollama-host http://192.168.1.100:11434

# An√°lisis completo con todas las opciones
python pdf_analyzer.py --pdf libro.pdf --out errores.txt --start-page 1 --end-page 50 --model mistral:7b --debug
```

## Formato de salida

El script genera un archivo de texto con el siguiente formato:

```
================================================================================
P√°gina 3
================================================================================

üìù Errores detectados por LanguageTool (2):
  ‚ùå "c√≥mmic"
     Tipo: Ortograf√≠a
     Posici√≥n: 127
     Sugerencia: comic|comi|c√≥mic

  ‚ùå "estare"
     Tipo: Ortograf√≠a
     Posici√≥n: 245
     Sugerencia: estar√©|estar

ü§ñ Errores de redacci√≥n detectados por LLM (1):
  ‚ùå "La investigaci√≥n fue realizada por nosotros durante el a√±o 2023 en el mes de enero"
     Tipo: LLM-Redundancia
     Sugerencia: La investigaci√≥n fue realizada en enero de 2023
     Raz√≥n: Redundancia temporal innecesaria y voz pasiva puede mejorarse
```

**Ventaja del an√°lisis h√≠brido**: El LLM detecta errores de redacci√≥n y estilo que LanguageTool no puede identificar, proporcionando un an√°lisis m√°s completo y profundo.

## Modelos Recomendados

| Modelo | Tama√±o | Velocidad | Calidad | Uso Recomendado |
|--------|--------|-----------|---------|-----------------|
| `llama3.2:3b` | 3 GB | Muy r√°pido | Buena | Pruebas y an√°lisis r√°pidos |
| `mistral:7b` | 7 GB | R√°pido | Muy buena | Balance velocidad/calidad |
| `mistral:latest` | 7 GB | R√°pido | Muy buena | Versi√≥n actualizada de Mistral |
| `gemma2:9b` | 9 GB | Moderado | Excelente | An√°lisis profundo |

## Por qu√© an√°lisis h√≠brido

El enfoque h√≠brido combina lo mejor de ambos mundos:

### LanguageTool
- R√°pido y eficiente
- Basado en reglas ling√º√≠sticas
- Alta precisi√≥n en errores ortogr√°ficos b√°sicos
- No requiere GPU

### Ollama LLMs
- Comprensi√≥n contextual profunda
- Detecci√≥n de problemas de estilo y coherencia
- Sugerencias inteligentes basadas en el contexto
- 100% privado y local
- Sin costos ni APIs de pago

### Juntos
Proporcionan un an√°lisis **completo** que cubre desde errores ortogr√°ficos b√°sicos hasta problemas complejos de redacci√≥n y estilo.

## Por qu√© language_tool_python

**`language-tool-python`** es la mejor opci√≥n para correcci√≥n ortogr√°fica en espa√±ol porque:

1. **IA y reglas ling√º√≠sticas**: Combina modelos basados en aprendizaje autom√°tico con reglas gramaticales y ortogr√°ficas espec√≠ficas del espa√±ol
2. **LanguageTool backend**: Es un frontend de [LanguageTool](https://languagetool.org/), una herramienta de c√≥digo abierto ampliamente reconocida
3. **Detecci√≥n contextual**: No solo identifica palabras mal escritas, sino tambi√©n errores gramaticales y estil√≠sticos
4. **Sugerencias inteligentes**: Proporciona m√∫ltiples sugerencias de correcci√≥n ordenadas por relevancia
5. **Mantenimiento activo**: Proyecto activamente mantenido con actualizaciones regulares
6. **Instalaci√≥n simple**: No requiere configuraci√≥n compleja, descarga autom√°ticamente los recursos necesarios

## Manejo de errores

El script incluye validaciones para:

- PDF no existente o corrupto
- Falta de conexi√≥n a Internet (LanguageTool descarga recursos en primera ejecuci√≥n)
- Ollama no accesible o sin modelos instalados
- P√°ginas ilegibles o con formato complejo
- Interrupciones del usuario (Ctrl+C)
- Errores de escritura en archivo de salida

## Limitaciones

- **Tama√±o recomendado**: PDFs de hasta ~300 p√°ginas. Documentos m√°s grandes pueden procesarse pero tardar√°n m√°s
- **Conexi√≥n a Internet**: La primera ejecuci√≥n de LanguageTool requiere conexi√≥n para descargar recursos
- **PDFs escaneados**: El script solo funciona con PDFs que contengan texto seleccionable. Para PDFs escaneados (im√°genes), se requiere OCR previo
- **Rendimiento**: El an√°lisis h√≠brido puede tomar 3-10 segundos por p√°gina dependiendo del modelo LLM usado
- **Ollama requerido**: El script requiere que Ollama est√© instalado y ejecut√°ndose con al menos un modelo descargado

## Soluci√≥n de problemas

### Error: "LanguageTool no puede inicializar"

**Causa**: Falta de conexi√≥n a Internet o recursos no descargados.

**Soluci√≥n**: Verifica tu conexi√≥n y ejecuta nuevamente. Los recursos se descargan autom√°ticamente la primera vez.

### Error: "No se pudo conectar a Ollama"

**Causa**: Ollama no est√° ejecut√°ndose o no es accesible desde WSL.

**Soluci√≥n**:
- Verifica que Ollama est√© ejecut√°ndose en Windows
- Ejecuta `python test_ollama_connection.py` para diagnosticar
- Consulta `CONFIGURACION_OLLAMA.md` para configuraci√≥n completa

### Error: "PDF no puede ser le√≠do"

**Causa**: PDF corrupto, protegido por contrase√±a, o es una imagen escaneada.

**Soluci√≥n**:
- Verifica que el PDF no est√© corrupto
- Remueve la contrase√±a si est√° protegido
- Para PDFs escaneados, usa herramientas OCR como Tesseract primero

### El script es muy lento

**Causa**: El an√°lisis con LLM es naturalmente m√°s lento que solo LanguageTool.

**Soluci√≥n**:
- Usa modelos m√°s peque√±os como `llama3.2:3b` para mayor velocidad
- Analiza solo rangos espec√≠ficos de p√°ginas con `--start-page` y `--end-page`
- Divide el PDF en secciones m√°s peque√±as

## Contribuciones

Para reportar bugs o sugerir mejoras, consulta la documentaci√≥n del proyecto.

## Licencia

Este script es de c√≥digo abierto y puede ser usado libremente para fines educativos y comerciales.
